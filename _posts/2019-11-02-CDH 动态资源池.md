---
layout:     post
title:      CDH 动态资源池
subtitle:   
date:       2019-11-02
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - CDH
    - 资源
    - bigdata
---

​		理想情况下，我们应用对Yarn资源的请求应该立刻得到满足，但现实情况资源往往是**有限**的，特别是在一个很繁忙的集群，一个应用资源的请求经常需要等待一段时间才能的到相应的资源。在Yarn中，负责给应用分配资源的就是 `Scheduler`。其实调度本身就是一个难题，很难找到一个完美的策略可以解决所有的应用场景。为此，Yarn提供了多种调度器和可配置的策略供我们选择。
在Yarn中有三种调度器可以选择：FIFO Scheduler ，Capacity Scheduler，FairScheduler。

- `FIFO Scheduler`：很好理解，任务先进先出，大任务会堵塞后面的其他任务
- `Capacity Scheduler` ：有一个**专门的队列**用来运行**小任务**，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间 ；`apache yarn` **默认调度器**
- `FairScheduler`： 为所有的应用分配**公平的资源** ， 每个应用有一定的资源使用(资源单指**内存**)

三种调度器可以在 `yarn-site.xml` 中设置

| 属性                                 | 值                                                           |
| ------------------------------------ | ------------------------------------------------------------ |
| yarn.resourcemanager.scheduler.class | org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler |

`CDH yarn` **默认调度器**是 `FairScheduler`，调度策略是 `DRF`：基于 `vcore` 和`内存`的策略。`CDH` 有个资源池的概念，默认是**静态资源池**。但用在生产中不合适，大部分使用的是**动态资源池**，何为动态：当其他队列的资源没有被使用时，运行中的作业可以去**占用**这些资源。根据实际情况，可以两种方式来划分队列：人员角色、项目角色

![](https://vendanner.github.io/img/CDH/dynamic_resource_pool.png)

![](https://vendanner.github.io/img/CDH/dynamic_resource_pool_config.png)

### 人员角色

项目中人员大致可以分为三种：测试、开发、生产，由此我们也可以将队列划分三种：`qa`、`dev`、`pro`。

#### `CDH` 设置

在web 界面创建相应的队列和 default(不在三种角色里的都用 default)，并设置**放置规则**

![](https://vendanner.github.io/img/CDH/create_resource_pool.png)

![](https://vendanner.github.io/img/CDH/refresh_dynamic_resource_pool.png)

创建`qa`、`dev`、`pro`、`default` 四个队列

先清空规则

![](https://vendanner.github.io/img/CDH/create_placement.png)

![](https://vendanner.github.io/img/CDH/refresh_dynamic_resource_rule.png)

规则如下：若用户组是 `qa`、`dev`、`pro`则放到对应的队列，否则放进 `default`

#### 用户设置

在web 界面设置的规则是根据**用户组**来确定放置的队列，那么我们就在机器添加三个用户组并用户添加打对应的组内。

>按人员角色分配这种方式，需要在**所有机器**上都设置所需的用户组和用户。

```shell
[root@hadoop001 ~]# groupadd dev
[root@hadoop001 ~]# groupadd qa
[root@hadoop001 ~]# groupadd pro
[root@hadoop001 ~]# useradd -g dev dev1
[root@hadoop001 ~]# useradd -g qa qa1
[root@hadoop001 ~]# useradd -g pro pro
```

#### 测试

```shell
[root@hadoop004 ~]# su - dev1
[dev1@hadoop004 ~]$ spark2-submit --master yarn --deploy-mode cluster 
--num-executors 3 --class org.apache.spark.examples.SparkPi 
examples/jars/spark-examples_2.11-2.4.0.cloudera2.jar
```

查看 yarn web界面，`dev1 用户`提交的任务进入 `dev 队列`

![](https://vendanner.github.io/img/CDH/dev_queue.png)

### 项目角色

每个**项目**建一个队列，假设公司当前有三个项目：`dw`、`ss`、`aw`。

#### `CDH` 设置

相同设置，最终队列如下

![](https://vendanner.github.io/img/CDH/project_resource_pool.png)

规则设置有所改变

![](https://vendanner.github.io/img/CDH/project_resource_rule.png)

注意规则是 ` Specified at run time `

#### 用户设置

> 这种方式不需要额外添加用户，但在项目增删时需要**更新队列**

#### 测试

```shell
[dev1@hadoop004 spark2]$ spark2-submit --queue dw --master yarn --deploy-mode cluster 
--num-executors 3 --class org.apache.spark.examples.SparkPi 
examples/jars/spark-examples_2.11-2.4.0.cloudera2.jar
```

![](https://vendanner.github.io/img/CDH/project_run_queue.png)







## 参考资料

 [YARN调度器(Scheduler)详解](https://www.cnblogs.com/lenmom/p/11285273.html) 