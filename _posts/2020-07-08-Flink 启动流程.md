---
layout:     post
title:      Flink 启动流程
subtitle:   
date:       2020-07-08
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Flink
    - bigdata
---

Flink 1.10

前面几篇文章从各个组件的角度阐述了 Flink 任务的启动，本节将以 `Flink On Yarn` 的 `Per Job` 模式将所有知识点串起来。

以下从本地和集群两个角度来说明

### 本地

```shell
flink run 
```

当执行上面的命令后，开始任务的提交：

- [Flink 启动流程之 flink run](https://vendanner.github.io/2020/07/02/Flink-启动流程之-flink-run/) 中最后是去执行任务的代码
- [深入剖析 Flink Straming WC流程](https://vendanner.github.io/2020/05/26/深入剖析-Flink-Straming-WC流程/) 中生成 `JobGraph`，并提交到集群；不同之处在于本例是 Yarn 集群

下面来说说在 Yarn 集群上，JobGraph 是如何提交的。此时的 Executor 是 `YarnJobClusterExecutor`，由于生成 `StreamGraph` 代码是相同的，直接从 `YarnJobClusterExecutor` 开始 (直接执行 flink run 是跑在yarn 集群的 per job任务)。

```java
// org.apache.flink.yarn.executors.YarnJobClusterExecutor
public class YarnJobClusterExecutor extends AbstractJobClusterExecutor<ApplicationId, YarnClusterClientFactory> {

	public static final String NAME = "yarn-per-job";

	public YarnJobClusterExecutor() {
		super(new YarnClusterClientFactory());
	}
}
// org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor
public class AbstractJobClusterExecutor<ClusterID, ClientFactory extends ClusterClientFactory<ClusterID>> implements PipelineExecutor {

	private static final Logger LOG = LoggerFactory.getLogger(AbstractJobClusterExecutor.class);
	private final ClientFactory clusterClientFactory;
	public AbstractJobClusterExecutor(@Nonnull final ClientFactory clusterClientFactory) {
		this.clusterClientFactory = checkNotNull(clusterClientFactory);
	}
	@Override
	public CompletableFuture<JobClient> execute(@Nonnull final Pipeline pipeline, @Nonnull final Configuration configuration) throws Exception {
		// 生成 jobgraph 过程后续介绍
    final JobGraph jobGraph = ExecutorUtils.getJobGraph(pipeline, configuration);
    // 获取 YarnClusterDescriptor，deployJobCluster 就提交 jobGraph 到yarn
    // 这里可以去看看 yarn-seesion 的启动流程，clusterClientFactory = 	YarnClusterClientFactory
		try (final ClusterDescriptor<ClusterID> clusterDescriptor = clusterClientFactory.createClusterDescriptor(configuration)) {
			final ExecutionConfigAccessor configAccessor = ExecutionConfigAccessor.fromConfiguration(configuration);
			// 计算内存，slot
      final ClusterSpecification clusterSpecification = clusterClientFactory.getClusterSpecification(configuration);
			final ClusterClientProvider<ClusterID> clusterClientProvider = clusterDescriptor
					.deployJobCluster(clusterSpecification, jobGraph, configAccessor.getDetachedMode());
			LOG.info("Job has been submitted with JobID " + jobGraph.getJobID());
			return CompletableFuture.completedFuture(
					new ClusterClientJobClientAdapter<>(clusterClientProvider, jobGraph.getJobID()));
		}
	}
}
```

至此本地的提交流程结束，结合源码可以封装个自己的 `Yarn` 提交代码。

### 集群

`clusterDescriptor.deployJobCluster` 执行时会执行 **ClusterEntrypoint**。[Flink 启动流程之 JobManager](https://vendanner.github.io/2020/06/04/Flink-启动流程之-JobManager/) 中介绍的是 `Standalone` 模式下，作为对比看看 **YarnJobClusterEntrypoint** 有什么不同。

```java
// org.apache.flink.yarn.entrypoint.YarnJobClusterEntrypoint
// ------------------------------------------------------------------------
//  The executable entry point for the Yarn Application Master Process
//  for a single Flink job.
// ------------------------------------------------------------------------
public class YarnJobClusterEntrypoint extends JobClusterEntrypoint {
  protected DefaultDispatcherResourceManagerComponentFactory createDispatcherResourceManagerComponentFactory(Configuration configuration) throws IOException {
	return DefaultDispatcherResourceManagerComponentFactory.createJobComponentFactory(
		YarnResourceManagerFactory.getInstance(),
    // 包含 JobGraph
		FileJobGraphRetriever.createFrom(configuration, getUsrLibDir(configuration)));
  }
...
  // Standalone 模式下相同步骤
}
```

> 最新版本1.11支持 Application 模式，可以将 `JobGraph` 生成也放到集群，减少本地压力。

### 总结

以下内存摘抄[参考资料一](https://www.cnblogs.com/leesf456/p/11136344.html)

#### 本地流程

- 与Session-Cluster模式类似，入口也为CliFrontend#main
- 解析处理参数
- 根据用户jar、main、程序参数、savepoint信息生成PackagedProgram
- 根据PackagedProgram创建JobGraph（对于非分离模式还是和Session模式一样，模式Session-Cluster）
- 获取集群资源信息(createClusterDescriptor，getClusterSpecification)
- 部署集群YarnClusterDesriptor#deployJobCluster -> AbstractYarnClusterDescriptor#deployInternal；后面流程与Session-Cluster类似，值得注意的是在AbstractYarnClusterDescriptor#startAppMaster中与Session-Cluster有一个显著不同的就是其会**将任务的JobGraph上传至Hdfs供后续服务端使用**

#### 远端流程

- 远端宿主在Container中的集群入口为**YarnJobClusterEntrypoint#main**
- ClusterEntrypoint#runClusterEntrypoint -> ClusterEntrypoint#startCluster启动集群
- 创建JobDispatcherResourceManagerComponentFactory（用于创建JobDispatcherResourceManagerComponent）
- 创建ResourceManager（YarnResourceManager）、Dispatcher（MiniDispatcher），其中在创建MiniDispatcher时会从之前的**JobGraph文件中读取出JobGraph**，并启动进行ZK选举
- **当为主时会调用Dispatcher#grantLeadership方法**
  - Dispatcher#recoverJobs恢复任务，获取JobGraph
  - Dispatcher#tryAcceptLeadershipAndRunJobs确认获取主并开始运行任务
    - Dispatcher#tryAcceptLeadershipAndRunJobs确认获取主并开始运行任务



## 参考资料

[【Flink】深入理解Flink-On-Yarn模式](https://www.cnblogs.com/leesf456/p/11136344.html)