---
layout:     post
title:      Azkaban 入门
subtitle:   
date:       2019-10-13
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Azkaban
    - 调度
    - bigdata
---

> https://azkaban.readthedocs.io/en/latest/getStarted.html#

### 安装

> https://azkaban.readthedocs.io/en/latest/getStarted.html#building-from-source

参考上面官方文档，下载编译安装即可。

在启动之前，先配个用户：

```xml
<!--  conf/azkaban-users.xml -->
<azkaban-users>
  <user groups="azkaban" password="azkaban" roles="admin" username="azkaban"/>
  <user password="metrics" roles="metrics" username="metrics"/>
  <!-- 新增 danner 用户，角色为 admin -->
  <user password="123456" roles="admin" username="danner"/>
  <role name="admin" permissions="ADMIN"/>
  <role name="metrics" permissions="METRICS"/>
</azkaban-users>
```

执行 `bin/start-solo.sh ` 启动，会有 `AzkabanSingleServer` 进程，默认是在 `8081` 端口

![](https://vendanner.github.io/img/azkaban/login.png)

上图蓝色框图内的文字和端口都可以在 `conf/azkaban.properties` 文件中配置

```shell
...
# 时区配置成上海
default.timezone.id=Asia/Shanghai
...
```



### 案例

> https://azkaban.readthedocs.io/en/latest/useAzkaban.html

按上面文档创建一个项目

![](https://vendanner.github.io/img/azkaban/create_project.png)

![](https://vendanner.github.io/img/azkaban/test001.png)

> https://azkaban.readthedocs.io/en/latest/createFlows.html

按照上面的官方文档**配置**，上传 `Flow` 即可执行。下面通过几个小案例来熟悉

#### `Hello Azkaban`

创建一个文件夹，包含两个文件，层级如下

```shell
hello_azkaban
  -- flow20.project    // 文件名固定
  -- basic.flow			// 以 flow 后缀名，yaml 格式
```

 `flow20.project` : 只写 `azkaban-flow-version` 版本号

```shell
azkaban-flow-version: 2.0
```

`basic.flow`： 任务的内容和依赖

```yaml
nodes:
  - name: jobA
    type: command
    config:
      command: echo "hello azkaban ..."
```

将 `hello_azkaban` 文件夹打包成 `zip` 格式，点击 `Upload` 按钮上传

![](https://vendanner.github.io/img/azkaban/upload_flow.png)

点击 `Execute Flow` 去执行，执行过程和结果被展示

![](https://vendanner.github.io/img/azkaban/job_flow_stat.png)

点击 `Log` 查看

![](https://vendanner.github.io/img/azkaban/hello_azkaban_log.png)

#### `Dependency`

上面的案例只是单独任务，若任务之间存在依赖该如何配置呢：`flow20.project` 内容不变，主要是 `basic.flow`

```yaml
nodes:
  - name: jobC
    type: noop
    # jobC depends on jobA and jobB
    dependsOn:
      - jobA
      - jobB

  - name: jobA
    type: command
    config:
      command: echo "This is an echoed text."

  - name: jobB
    type: command
    config:
      command: pwd
```

`jobC`  依赖 `jobA` 和 `jobB`，打包上传后在 `UI`  上看看是如何体现

![](https://vendanner.github.io/img/azkaban/dependency_job.png)

看任务的执行：`jobA` 和 `jobB` 同时执行，但`jobC` 是在前两个任务都执行完后才执行

![](https://vendanner.github.io/img/azkaban/dependency_time.png)

#### MR

如果任务是 `MR` 该如何配置呢，很简单只是一条**命令**即可

```yaml
nodes:
  - name: MR
    type: command
    config:
      command: /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/bin/hadoop jar /home/hadoop/lib/hadoop/G7-41-dwt.jar com.danner.bigdata.hadoop.homework.ETLApp /project/hadoop/access/log/20190917 /project/hadoop/access/out/20190917 /tmp/data/ip.txt
```

注意：命令和 `jar` 要写**绝对路径**

#### Hive

`Hive` 也可以用命令或者 `shell` 搞定，但这里我换一种方式

> https://azkaban.readthedocs.io/en/latest/jobTypes.html#hive-type  == > `New Hive Jobtype`

这里需要注意，像 `hive`、`spark`、`pig` 这种类型是需要插件支持的，所以要先编译插件

- 参考资料三编译插件，需单独编译(插件是放在 `azkaban/plugins` 下，默认无插件)
- 配置好 **环境变量** 和 `classpath`

运行环境配置好后，跟之前一眼还是写配置

```shell
hive
  -- flow20.project    
  -- basic.flow	
  -- hive.shell
```

```yaml
# basic.flow	
nodes:
  - name: Hive
    # hive 这个 type 要插件支持且与 azkaban/plugins/jobtypes 目录下的名称一致
    type: hive
    config:
      hive.script: hive.shell
```

```shell
# hive.shell
# sql 即可；类似在 hive 终端执行
select * from danner_db.platform_stat;
```



## 参考资料

[Azkaban源码分析1](https://zhuanlan.zhihu.com/p/22254898)

[Azkaban源码分析2](https://zhuanlan.zhihu.com/p/22268277)

[azkaban3.57及3.0插件的编译](https://blog.csdn.net/weixin_39778085/article/details/90312364)

