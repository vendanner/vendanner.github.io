---
layout:     post
title:      Hadoop 集群创建
subtitle:   Hadoop 集群创建粗略笔记
date:       2018-02-16
author:     daner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Hadoop
    - 大数据
    - YARN
---

## 设置hostname、Ip


### 先更改，对应的网络名称便于后续维护(每台机子都要执行)：
`sudo gedit /etc/sysconfig/network`
>TWORKING=yes

>HOSTNAME=danner000


### 在namenode 的主机设置hostname和ip：
`vi /etc/hosts`
>192.168.22.147 danner000	

>192.168.22.149 danner001


## 设置ssh 免密码登录
设定**danner000**为Master；在每台机器运行：`ssh-keygen –t rsa` ,生成ssh 密钥。把本地主机的公钥复制到目标主机的`authorized_keys`文件下,实现本地主机**免密**登陆：
>ssh-copy-id –i ~/.ssh/id_rsa.pub danner000

>ssh-copy-id –i ~/.ssh/id_rsa.pub danner001

以上代码是在**danner000**机器上执行;在后续的ssh 免密登陆过程中如果提示`Agent admitted failure to sign using the key`,则利用` ssh-add   ~/.ssh/id_rsa`把私钥加进去。


### 关闭防火墙
**线上环境不准如此设置**，只开放对应端口即可。

Centos7以下：
>service iptables stop  	即时生效，重启后复原

>chkconfig iptables off 	永久性生效，重启后不会复原

centos7 及以上：
>systemctl stop firewalld.service 	#停止firewall

>systemctl disable firewalld.service #禁止firewall开机启动


## jdk 环境(hadoop版本>=2.7 jdk7 )
- [下载](https://download.oracle.com/otn/java/jdk/7u79-b15/jre-7u79-linux-x64.tar.gz?AuthParam=1550277880_b145349131f84ce54f78a006e0e7240b) `jdk-7u79-linux-x64.tar.gz`
- 使用tar 命令解压到 ~/app 目录下
- 在`~/.bash_profile`配置**Java**环境变量：`PATH=$PATH:JAVA_HOME/bin`



## 配置hadoop集群


### 安装Hadoop
- [下载](http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gz) `hadoop-2.6.0-cdh5.7.0.tar.gz`
- 使用tar命令解压到~/app 目录
- 在`~/.bash_profile`配置hadoop环境变量：
>PATH=$PATH:HADOOP_HOME/bin


### 修改hadoop配置文件
在`HADOOP_HOME/etc/hadoop`目录下

- `hadoop_env.sh` 修改java_home：
> EXPORT JAVA_HOME=/home/danner/app/jdk1.7.0_79

- `core-site.xml`:配置namenode

```

	<configuration>
    	<property>
        	<description>默认文件系统及端口</description> 
        	<name>fs.default.name</name>
        	<value>hdfs://danner000:8020/</value>
       </property>
	</configuration>

```

- `hdfs-site.xml`:配置**namenode datanode**数据目录

```

  	<property>
        <description>namedoe 存储永久性的元数据目录列表</description> 
        <name>dfs.namenode.name.dir</name>
        <value>/home/danner/app/tmp/dfs/name/</value>
    </property>

    <property>
        <description>datanode 存放数据块的目录列表</description> 
        <name>dfs.datanode.data.dir</name>
        <value>/home/danner/app/tmp/dfs/data/</value>
	</property>


```

- `yarn-site.xml`

```

<property> 
        <name>yarn.nodemanager.aux-services</name> 
        <value>mapreduce_shuffle</value> 
    </property> 
	<property>  
        <description>The hostname of the RM.</description>  
        <name>yarn.resourcemanager.hostname</name>  
        <value>danner000</value>  
</property>

```

- `mapred-site.xml`:

```

<property> 
        <description>MapReduce 执行框架设为 Hadoop YARN. </description> 
        <name>mapreduce.framework.name</name> 
        <value>yarn</value> 
</property>

```

- slave：配置从节点(3个)
> danner000
>
> danner001
>
> danner100

- 分发hadoop配置: 直接将配置好的Hadoop copy 到slave 机器上
> scp -r ~/app danner001:~/
> 
> scp -r ~/app danner100:~/
> 
> scp  ~/.bash_profile danner001:~/
> 
> scp  ~/.bash_profile danner100:~/






### Hadoop集群的启动和停止
- 对nanedode做格式化：只要在danner000机器上执行
> hdfs namenode –format: 会在对应hdfs目录下生成” dfs/name/current”

- 启动hadoop集群： 只要在danner000机器上执行
> sbin/start-all.sh

- 验证集群启动：`jps`

输出如下：

```

danner000:
	51835 DataNode
	51997 SecondaryNameNode
	52236 NodeManager
	51713 NameNode
	52139 ResourceManager
Danner001:
	11140 NodeManager
	11050 DataNode
Danner100:
	3980 DataNode
	4074 NodeManager
Webui：danner000:50070; danner000:8088

```
- 停止：`sbin/stop-all.sh`


### mapreduce job history 配置(mapreduce-site.xml)
``` 
<property>
  <name>mapreduce.jobhistory.address</name>
  <value>danner000:10020</value>
  <description>MapReduce JobHistory Server IPC host:port</description>
</property>

<property>
  <name>mapreduce.jobhistory.webapp.address</name>
  <value>danner000:19888</value>
  <description>MapReduce JobHistory Server Web UI host:port</description>
</property>

<property>
    <name>mapreduce.jobhistory.done-dir</name>
    <value>/history/done</value>
</property>

<property>
    <name>mapreduce.jobhistory.intermediate-done-dir</name>
<value>/history/done_intermediate</value>
</property>

```

配置好后，需单独执行:`./mr-jobhistory-daemon.sh start historyserver`

关闭job history：`./mr-jobhistory-daemon.sh stop historyserver`



