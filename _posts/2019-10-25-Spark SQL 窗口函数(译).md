---
layout:     post
title:      Spark SQL 窗口函数(译)
subtitle:  
date:       2019-10-25
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Spark
    - SQL
    - bigdata
---

>  https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html 

### 窗口函数

来两个小需求来介绍窗口函数强大的功能

![](https://vendanner.github.io/img/SparkSQL/product_revenue.png)

- 求每个标签下，收入排行最高和第二高



#### 需求一

实际需求就是分组排序(注意不是求 TopN，所以这里用 dense_rank)，需要分组排序然后对 index <= 2 过滤

```shell
SELECT
  product,
  category,
  revenue
FROM (
  SELECT
    product,
    category,
    revenue,
    dense_rank() OVER (PARTITION BY category ORDER BY revenue DESC) as rank
  FROM productRevenue) tmp
WHERE
  rank <= 2
```

`dense_rank() OVER` 简单解决分组排序问题，再做过滤即可解决

![](https://vendanner.github.io/img/SparkSQL/product_revenue_top2.png)

#### 需求二



```python
import sys
from pyspark.sql.window import Window
import pyspark.sql.functions as func
windowSpec = 
  Window 
    .partitionBy(df['category']) 
    .orderBy(df['revenue'].desc()) 
    .rangeBetween(-sys.maxsize, sys.maxsize)
dataFrame = sqlContext.table("productRevenue")
revenue_difference = 
  (func.max(dataFrame['revenue']).over(windowSpec) - dataFrame['revenue'])
dataFrame.select(
  dataFrame['product'],
  dataFrame['category'],
  dataFrame['revenue'],
  revenue_difference.alias("revenue_difference"))
```



