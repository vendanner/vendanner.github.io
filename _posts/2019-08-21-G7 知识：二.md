---
layout:     post
title:      G7 知识：二
subtitle:   HDFS
date:       2019-08-21
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 大数据
    - Hadoop
    - HDFS
    - Yarn
    - G7
---

一些小姿势

### hdfs 常用命令整理
	
#### hdfs haadmin

> run a DFS HA admin client

	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin
	Usage: DFSHAAdmin [-ns <nameserviceId>]
	    [-transitionToActive <serviceId> [--forceactive]]
	    [-transitionToStandby <serviceId>]
	    [-failover [--forcefence] [--forceactive] <serviceId> <serviceId>]
	    [-getServiceState <serviceId>]
	    [-checkHealth <serviceId>]
	    [-help <command>]
	
	Generic options supported are
	-conf <configuration file>     specify an application configuration file
	-D <property=value>            use value for given property
	-fs <local|namenode:port>      specify a namenode
	-jt <local|resourcemanager:port>    specify a ResourceManager
	-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
	-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
	-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

查看 `namenode` 状态

	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin -getServiceState nn1
	active

切换 `active namenode`
	
	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin -failover nn1 nn2
	Failover to NameNode at danner002/172.16.19.36:8020 successful
	# 切换成功，查看状态是否改变
	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin -getServiceState nn2
	active								


#### hdfs fsck
> run a DFS filesystem checking utility



### yarn 常用命令整理

### 整理故障案例

### 压缩哪几种，

编译后的  执行 hadoop checknative 命令 输出结果是什么？

### standby 节点
能不能直接读 hdfs dfs -ls hdfs://ruozedata002:8020/                 ？
能不能直接写 hdfs dfs -put xxx.log hdfs://ruozedata002:8020/    ?


### 什么是hdfs的安全模式？如何进，如何离开？
那么在安全模式下，能读文件吗 ？能写文件吗？


### hdfs ha启动过程中，那么多进程，先后顺序关系是什么? dn进程是最后启动吗？
	
`namenode` -> `datanode` -> `journalnode` -> `ZKFC`

	Starting namenodes on [danner001 danner002]
	danner001: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-namenode-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-namenode-izbp13e6ad3yxuuc3va7bfz.out
	danner003: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-datanode-izbp13e6ad3yxuuc3va7bgz.out
	danner001: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-datanode-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-datanode-izbp13e6ad3yxuuc3va7bfz.out
	Starting journal nodes [danner001 danner002 danner003]
	danner003: starting journalnode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-journalnode-izbp13e6ad3yxuuc3va7bgz.out
	danner001: starting journalnode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-journalnode-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting journalnode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-journalnode-izbp13e6ad3yxuuc3va7bfz.out
	Starting ZK Failover Controllers on NN hosts [danner001 danner002]
	danner001: starting zkfc, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-zkfc-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting zkfc, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-zkfc-izbp13e6ad3yxuuc3va7bfz.out

> 停止的顺序与启动相同