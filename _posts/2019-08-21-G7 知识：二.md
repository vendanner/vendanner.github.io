---
layout:     post
title:      G7 知识：二
subtitle:   HDFS
date:       2019-08-21
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 大数据
    - Hadoop
    - HDFS
    - Yarn
    - G7
---

一些小姿势

### hdfs 常用命令整理
	
#### hdfs haadmin

> run a DFS HA admin client

	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin
	Usage: DFSHAAdmin [-ns <nameserviceId>]
	    [-transitionToActive <serviceId> [--forceactive]]
	    [-transitionToStandby <serviceId>]
	    [-failover [--forcefence] [--forceactive] <serviceId> <serviceId>]
	    [-getServiceState <serviceId>]
	    [-checkHealth <serviceId>]
	    [-help <command>]
	
	Generic options supported are
	-conf <configuration file>     specify an application configuration file
	-D <property=value>            use value for given property
	-fs <local|namenode:port>      specify a namenode
	-jt <local|resourcemanager:port>    specify a ResourceManager
	-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
	-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
	-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

查看 `namenode` 状态

	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin -getServiceState nn1
	active

切换 `active namenode`
	
	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin -failover nn1 nn2
	Failover to NameNode at danner002/172.16.19.36:8020 successful
	# 切换成功，查看状态是否改变
	[hadoop@izbp13e6ad3yxuuc3va7bez hadoop]$ hdfs haadmin -getServiceState nn2
	active								


#### hdfs fsck

> run a DFS filesystem checking utility

查看整个集群文件状态

	[hadoop@localhost ~]$ hdfs fsck /
	19/08/26 02:30:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	Connecting to namenode via http://192.168.22.147:50070/fsck?ugi=hadoop&path=%2F
	FSCK started by hadoop (auth:SIMPLE) from /192.168.22.147 for path / at Mon Aug 26 02:30:54 PDT 2019
	..............Status: HEALTHY
	 Total size:    173449617 B
	 Total dirs:    20
	 Total files:   14
	 Total symlinks:                0
	 Total blocks (validated):      14 (avg. block size 12389258 B)
	 Minimally replicated blocks:   14 (100.0 %)
	 Over-replicated blocks:        0 (0.0 %)
	 Under-replicated blocks:       0 (0.0 %)
	 Mis-replicated blocks:         0 (0.0 %)
	 Default replication factor:    1
	 Average block replication:     1.0
	 Corrupt blocks:                0
	 Missing replicas:              0 (0.0 %)
	 Number of data-nodes:          1
	 Number of racks:               1
	FSCK ended at Mon Aug 26 02:30:54 PDT 2019 in 14 milliseconds


The filesystem under path '/' is HEALTHY

	[hadoop@izbp1ds3ppdemdhy7lsoofz ~]$ hdfs fsck /jps.sh -files -locations -blocks -racks
	Connecting to namenode via http://danner002:50070/fsck?ugi=hadoop&files=1&locations=1&blocks=1&racks=1&path=%2Fjps.sh
	FSCK started by hadoop (auth:SIMPLE) from /172.16.19.39 for path /jps.sh at Mon Aug 26 23:56:53 CST 2019
	/jps.sh 436 bytes, 1 block(s):  Under replicated BP-1385507047-172.16.19.38-1566375335770:blk_1073741827_1003. Target Replicas is 3 but found 2 live replica(s), 0 decommissioned replica(s), 0 decommissioning replica(s).
	0. BP-1385507047-172.16.19.38-1566375335770:blk_1073741827_1003 len=436 Live_repl=2 [/default-rack/172.16.19.36:50010, /default-rack/172.16.19.37:50010]

### yarn 常用命令整理

#### yarn rmadmin

强制设置 `rm2` 为 `active resourcemanager`

	yarn rmadmin -transitionToActive  --forcemanual  rm2

#### yarn application

列出运行的任务 `id`
	
	yarn application -list 

#### yarn logs

查看 `jobId ` 任务日志(`jobId` 是上面命令的输出)

	yarn logs -applicationId jobId 



### 压缩算法

|  压缩算法  | 工具  |算法 |扩展名  |是否支持分割  |Hadoop 编码/解码器  |
|  ----  | ----  |----  |----  |----  |----  |
| DEFLATE  | N/A |DEFLATE |.deflate |No |org.apache.hadoop.io.compress.DefaultCodec |
| gzip  | gzip |DEFLATE |.gz |No |org.apache.hadoop.io.compress.GzipCodec |
| bzip2  | bzip2 |bzip2 |.bz2 |No |org.apache.hadoop.io.compress.BZip2Codec |
| LZO  | Lzop |LZO |.lzo |Yes(if index) |com.hadoop.compressiion.lzo.LzoCodec |
| LZ4  | N/A |LZ4 |.lz4 |No |org.apache.hadoop.io.compress.Lz4Codec |
| Snappy  | N/A |Snappy |.snappy |No |org.apache.hadoop.io.compress.SnappyCodec |

- gzip
	- 压缩比在四种压缩方式中**较高**；`hadoop` 本身支持，在应用中处理 `gzip`格式的文件就和直接处理文本一样；有 `hadoop native` 库；大部分 `linux` 系统都**自带** `gzip`命令，**使用方便**
	- 不支持 `split`
- bzip2
	- **支持** `split`；具有**很高的压缩率**，比 `gzip`压缩率都高；`hadoop` 本身支持，但**不支持** `native`；在 `linux` 系统下自带 `bzip2`命令，**使用方便**
	- **压缩/解压速度慢**；**不支持** `native`
- lzo
	- **压缩/解压速度也比较快**，合理的压缩率；**支持** `split`，是 `hadoop` 中**最流行的压缩格式**；支持 `hadoop native` 库；需要在 `linux`系统下自行安装 `lzop`命令，使用方便
	- **压缩率**比 `gzip` 要**低**；`hadoop` **本身不支持**，需要安装；`lzo` 虽然支持 `split`，但需要对 `lzo` 文件**建索引**，否则 `hadoop`也是会把 `lzo` 文件看成一个普通文件（为了支持 `split`需要建索引，需要指定 `inputformat` 为 `lzo` 格式）
- snappy
	- **压缩速度快**；**支持** `hadoop native`库
	- **不支持** `split`；**压缩比低**；`hadoop` **本身不支持**，需要安装；`linux` 系统下**没有**对应的命令

下面是这几种压缩方式对比

![](https://vendanner.github.io/img/hadoop/compress1.png)

![](https://vendanner.github.io/img/hadoop/compress2.png)

> 压缩比越高，压缩时间越长，压缩比：Snappy > LZ4 > LZO > GZIP > BZIP2


`hadoop checknative` 显示支持的压缩格式

	[hadoop@hadoop001 ~]$ hadoop checknative
	19/04/07 17:50:08 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
	19/04/07 17:50:08 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
	Native library checking:
	hadoop:  true /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/lib/native/libhadoop.so.1.0.0
	zlib:    true /lib64/libz.so.1
	snappy:  true /usr/lib64/libsnappy.so.1
	lz4:     true revision:99
	bzip2:   true /lib64/libbz2.so.1
	openssl: true /usr/lib64/libcrypto.so



### standby 节点

在实际的场景中我们能直接操作 `standby namenode` 吗？

> danner001 是 standby namenode，danner002 是 active namenode

	[hadoop@izbp1ds3ppdemdhy7lsoofz hadoop]$ hdfs dfs -ls hdfs://danner002:8020
	Found 2 items
	drwx------   - hadoop hadoop          0 2019-08-24 18:24 hdfs://danner002:8020/user/hadoop/.Trash
	-rw-r--r--   3 hadoop hadoop         70 2019-08-24 18:19 hdfs://danner002:8020/user/hadoop/HDFS_HA.log

	[hadoop@izbp1ds3ppdemdhy7lsoofz hadoop]$ hdfs dfs -ls hdfs://danner001:8020
	ls: Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

由此可见，无法**直接查看** `standby namenode`

	[hadoop@izbp1ds3ppdemdhy7lsoofz hadoop]$ hdfs dfs -put jps.sh hdfs://danner002:8020/
	[hadoop@izbp1ds3ppdemdhy7lsoofz hadoop]$ hdfs dfs -ls hdfs://danner002:8020/
	Found 3 items
	-rw-r--r--   3 hadoop hadoop        436 2019-08-26 23:01 hdfs://danner002:8020/jps.sh
	
	[hadoop@izbp1ds3ppdemdhy7lsoofz hadoop]$ hdfs dfs -put start_cluster.sh hdfs://danner001:8020/
	put: Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

同样无法**直接操作** `standby namenode`


### hdfs的安全模式

**安全模式**是 `HDFS` 所处的一种**特殊状态**。在这种状态下，文件系统**只接受读数据请求**，而**不接受删除、修改**等变更请求。在 `NameNode` 主节点启动时，`HDFS` 首先进入**安全模式**，`DataNode` 在启动的时候会向 `namenode` **汇报**可用的 `block` 等状态，当整个系统达到**安全标准**时，`HDFS` **自动离开安全模式**。要离开安全模式，需要满足以下**条件**：
 
- 达到**副本数量**要求的 `block` 比例满足要求； 
- 可用的 `datanode` **节点数**满足配置的数量要求； 
- 以上两个条件满足后**维持的时间**达到配置的要求。

> hadoop dfsadmin -safemode <command>

	hadoop dfsadmin -safemode get	// 查看当前状态
	hadoop dfsadmin -safemode enter	// 进入安全模式
	hadoop dfsadmin -safemode leave	// 强制离开安全模式
	hadoop dfsadmin -safemode wait	// 一直等待直到安全模式结束

**启动日志**

	# 进入安全模式
	
	2019-08-26 22:34:44,391 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
	The reported blocks 2 has reached the threshold 0.9990 of total blocks 2. The number of live datanodes 2 has reached the minimum number 0. 
	In safe mode extension. Safe mode will be turned off automatically in 9 seconds.

	# 退出安全模式 

	2019-08-26 22:34:54,393 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 41 secs
	2019-08-26 22:34:54,393 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
	2019-08-26 22:34:54,393 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 2 datanodes
	2019-08-26 22:34:54,393 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks

### hdfs ha 启动过程
	
`namenode` -> `datanode` -> `journalnode` -> `ZKFC`

	Starting namenodes on [danner001 danner002]
	danner001: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-namenode-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-namenode-izbp13e6ad3yxuuc3va7bfz.out
	danner003: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-datanode-izbp13e6ad3yxuuc3va7bgz.out
	danner001: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-datanode-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-datanode-izbp13e6ad3yxuuc3va7bfz.out
	Starting journal nodes [danner001 danner002 danner003]
	danner003: starting journalnode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-journalnode-izbp13e6ad3yxuuc3va7bgz.out
	danner001: starting journalnode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-journalnode-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting journalnode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-journalnode-izbp13e6ad3yxuuc3va7bfz.out
	Starting ZK Failover Controllers on NN hosts [danner001 danner002]
	danner001: starting zkfc, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-zkfc-izbp13e6ad3yxuuc3va7bez.out
	danner002: starting zkfc, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/hadoop-hadoop-zkfc-izbp13e6ad3yxuuc3va7bfz.out

> 停止的顺序与启动相同

### 整理故障案例


## 参考资料
[大数据压缩，你们真的了解吗？](https://ruozedata.github.io/2018/04/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%EF%BC%8C%E4%BD%A0%E4%BB%AC%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9F/)<br>
[HDFS安全模式详解](https://blog.csdn.net/bingduanlbd/article/details/51900512)