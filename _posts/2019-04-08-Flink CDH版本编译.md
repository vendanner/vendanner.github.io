---
layout:     post
title:      Flink CDH版本编译
subtitle:   
date:       2019-11-08
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Flink
    - CDH
    - bigdata
---

>  https://ci.apache.org/projects/flink/flink-docs-stable/flinkDev/building.html 

### 环境

- `maven`：`3.x`就可以，但最好是 `3.2.5`，不同版本对编译有[影响]( https://ci.apache.org/projects/flink/flink-docs-release-1.9/flinkDev/building.html#dependency-shading )

- `java`：至少 ` jdk1.8.0_111`， 否则报`flink flink-table-api-java: Compilation failure`

### 下载

可以选在在[官网]( https://flink.apache.org/downloads.html ) 或者 `github` 直接拉

```shell
git clone https://github.com/apache/flink
```

### 编译

#### `flink shaded `

我们需要编译的是`CDH`版本，而其  `flink-shaded-hadoop-2 ` 的 jar 在 `mvn 仓库`是没有提供的，需要自己编译。

 不同的 Flink 版本使用的 Flink-shaded不同，1.9.0 版本使用 7.0 

>  https://mirrors.tuna.tsinghua.edu.cn/apache/flink/flink-shaded-7.0/flink-shaded-7.0-src.tgz 

解压后在 `pom.xml` 文件添加 `CDH 源`

```shell
<profile>
	<id>vendor-repos</id>
	<activation>
		<property>
			<name>vendor-repos</name>
		</property>
	</activation>
	<!-- Add vendor maven repositories -->
	<repositories>
		<!-- Cloudera -->
		<repository>
			<id>cloudera-releases</id>
			<url>https://repository.cloudera.com/artifactory/cloudera-repos</url>
			<releases>
				<enabled>true</enabled>
			</releases>
			<snapshots>
				<enabled>false</enabled>
			</snapshots>
		</repository>
		<!-- Hortonworks -->
		<repository>
			<id>HDPReleases</id>
			<name>HDP Releases</name>
			<url>https://repo.hortonworks.com/content/repositories/releases/</url>
			<snapshots><enabled>false</enabled></snapshots>
			<releases><enabled>true</enabled></releases>
		</repository>
		<repository>
			<id>HortonworksJettyHadoop</id>
			<name>HDP Jetty</name>
			<url>https://repo.hortonworks.com/content/repositories/jetty-hadoop</url>
			<snapshots><enabled>false</enabled></snapshots>
			<releases><enabled>true</enabled></releases>
		</repository>
		<!-- MapR -->
		<repository>
			<id>mapr-releases</id>
			<url>https://repository.mapr.com/maven/</url>
			<snapshots><enabled>false</enabled></snapshots>
			<releases><enabled>true</enabled></releases>
		</repository>
	</repositories>
</profile>
```

> mvn  clean install -DskipTests -Drat.skip=true -Pvendor-repos  -Dhadoop.version=2.6.0-cdh5.15.1

编译成功后，会自动将 `flink-shaded-hadoop-2-uber-2.6.0-cdh5.15.1-7.0.jar` 移动到本地maven 仓库

#### `flink` 编译

有相关的 `CDH jar` 之后，可以开始正式编译 flink

> mvn clean install -DskipTests \
>
> -Pvendor-repos -Drat.skip=true \
>
> -Pinclude-hadoop \
>
> -Dhadoop.version=2.6.0-cdh5.15.1
>
> 编译成功后，如果 mvn 是 3.3.X 以上，还需要在 flink-dist 目录执行
>
> mvn clean install

编译过程中提示有jar 无法下载，不需要的模块直接注释不去下载；如果模块是必要的，可以手动下载安装到本地仓库，以 `hadoop-mapreduce-client-core-2.6.0-cdh5.15.1` 为例

```shell
mvn install:install-file \
-DgroupId=org.apache.hadoop \
-DartifactId=hadoop-mapreduce-client-core \
-Dversion=2.6.0-cdh5.15.1 \
-Dpackaging=jar \
-Dfile=/.../hadoop-mapreduce-client-core-2.6.0-cdh5.16.1.jar
```

编译成功，输出目录 ` flink-dist/target/flink-1.9.1-bin `就是可以部署的 `flink bin`

 