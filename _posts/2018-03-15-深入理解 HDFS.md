---
layout:     post
title:      深入理解 HDFS
subtitle:   
date:       2018-03-15
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Hadoop
    - HDFS
---

Hadoop 的三架马车：HDFS、MR、YARN，实现分布式**存储**、**计算**、**调度**。大数据发展至今组件日益成熟，但 HDFS 在存储领域还是一枝独秀。本文从 HDFS 启动流程的角度分析其运行机制。

### NameNode

```java
// org.apache.hadoop.hdfs.server.namenode.NameNode
/**
 * NameNode 控制两个关键的 Table
 * filename -> blocksequence (namespace/文件到 block 映射)
 * block -> machinelist ("inodes"/ block 到 DataNode 映射)
 * 第一张表存储在磁盘中，非常重要；第二张表会在每次启动时重新构建 (DN 向 NN 汇报自身 block 信息)
 **/
public class NameNode implements NameNodeStatusMXBean {
	protected FSNamesystem namesystem;              // 文件系统管理: 元数据管理
  protected NameNodeHttpServer httpServer;        // http server
  // NameNode RPCServer，实现很多协议
  private NameNodeRpcServer rpcServer;
    ClientProtocol          // 客户端访问操作
    DatanodeProtocol        // DataNode 通信协议
    HAServiceProtocol       // 实现 HA 协议
    ...
  protected void initialize(Configuration conf) throws IOException {
    ...
    // 启动 HttpServer，默认 50070 端口；
    if (NamenodeRole.NAMENODE == role) {
      startHttpServer(conf);
    }
    ...
    // FSNamesystem 元数据 => FSNamesystem.loadFromDisk(conf)
    loadNamesystem(conf);
    // NameNodeRpcServer => new NameNodeRpcServer(conf, this)
    rpcServer = createRpcServer(conf);
    if (clientNamenodeAddress == null) {
      // This is expected for MiniDFSCluster. Set it now using 
      // the RPC server's bind address.
      clientNamenodeAddress = 
          NetUtils.getHostPortString(rpcServer.getRpcAddress());
      LOG.info("Clients are to use " + clientNamenodeAddress + " to access"
          + " this namenode/service.");
    }
    if (NamenodeRole.NAMENODE == role) {
      httpServer.setNameNodeAddress(getNameNodeAddress());
      httpServer.setFSImage(getFSImage());
    }
    ...
    // 
    startCommonServices(conf);
  }
}
```

- **HttpServer**：HDFS WebUI 所示，默认端口 50070，实现很多 API 供查询 HDFS 使用
- **FSNamesystem**：元数据：`fsImage`，**blockManager**
- **NameNodeRpcServer**：处理 NameNode 所有 RPC 请求
- **安全模式**：
  - 可用 block 少于设定阈值
  - DataNode 正常工作不少于设定阈值；一般不设置，默认 0
  - NamaNode 元数据磁盘是否充足（至少一个磁盘空闲空间大于 100M）

![](https://vendanner.github.io/img/hadoop/namenode_start.jpg)

#### 元数据

HDFS 是分布式文件系统，必然有文件的元数据信息。

```java
// org.apache.hadoop.hdfs.server.namenode.FSNamesystem
/* 
 * FSNamesystem 记录 DataNode 操作：增删改 data
 * 重要的表：
 * 1）磁盘上记录 文件 -> block list 映射
 * 2）可用的 block (block 到文件映射)
 * 3）block -> datanode 映射 （内存中，datanode 报告后会更新）
 * 4）datanode -> 映射
 * 5）datanode 心跳 LRU
 */
public class FSNamesystem implements Namesystem, FSNamesystemMBean,
  NameNodeMXBean {
  // standby NameNode 同步 editlog
  private EditLogTailer editLogTailer = null;   
  // 非常重要：Block 和 DataNode 管理
  private final BlockManager blockManager;
  // fsimage
  private final FSImage fsImage;
    
  static FSNamesystem loadFromDisk(Configuration conf) throws IOException {
    ...
    // 合并磁盘 image + editlog = 内存 fsimage
    // 创建新 editlog
    FSImage fsImage = new FSImage(conf,
        // namenode 本地磁盘空间：dfs.namenode.name.dir
        FSNamesystem.getNamespaceDirs(conf),
        // 本地 editlog 空间：dfs.namenode.edits.dir
        FSNamesystem.getNamespaceEditsDirs(conf));
    // 创建 BlockManager，其包含 DatanodeManager 管理 datanode
    FSNamesystem namesystem = new FSNamesystem(conf, fsImage, false);
    StartupOption startOpt = NameNode.getStartupOption(conf);
    if (startOpt == StartupOption.RECOVER) {
      namesystem.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
    }

    try {
      namesystem.loadFSImage(startOpt);
    } catch (IOException ioe) {
      LOG.warn("Encountered exception loading fsimage", ioe);
      fsImage.close();
      throw ioe;
    }
    ... 
    return namesystem;
  }
}
```

#### NameNodeRpcServer

NameNodeRpcServer 处理 NameNode 所有 RPC 调用。

```java
// org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer
/** 处理 DataNode RPC 请求 */
private final RPC.Server serviceRpcServer;
/** 处理 客户端 RPC 请求 */
protected final RPC.Server clientRpcServer;
// 标准 hadoop RPC 创建方式
// 当前只是创建，后续会添加很多协议
this.serviceRpcServer = new RPC.Builder(conf)
  .setProtocol(
      org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB.class)
  .setInstance(clientNNPbService)
  .setBindAddress(bindHost)
  .setPort(serviceRpcAddr.getPort()).setNumHandlers(serviceHandlerCount)
  .setVerbose(false)
  .setSecretManager(namesystem.getDelegationTokenSecretManager())
  .build();


this.clientRpcServer = new RPC.Builder(conf)
  .setProtocol(
      org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB.class)
  .setInstance(clientNNPbService)
  .setBindAddress(bindHost)
  .setPort(rpcAddr.getPort()).setNumHandlers(handlerCount)
  .setVerbose(false)
  .setSecretManager(namesystem.getDelegationTokenSecretManager())
  .build();
```

#### 安全模式

HDFS 启动时先进入**安全模式**，满足条件才切换到正常模式

```java
// org.apache.hadoop.hdfs.server.namenode.FSNamesystem
void startCommonServices(Configuration conf, HAContext haContext) throws IOException {
  ...
  try {
    // 检查 namanode 元数据磁盘是否充足(editlog)
    nnResourceChecker = new NameNodeResourceChecker(conf);
    // 至少有一个磁盘的的元数据空闲空间 > 100M
    checkAvailableResources();
    ...
    // hdfs 安全模式，非常重要
    setBlockTotal();
    // 启动重要服务：datanodeManage heartbeatManager（心跳检测线程）
    blockManager.activate(conf);
  } finally {
    writeUnlock();
  }
  ...
}
public void setBlockTotal() {
  // safeMode is volatile, and may be set to null at any time
  SafeModeInfo safeMode = this.safeMode;
  if (safeMode == null)
    return;
  // getCompleteBlocksTotal 获取正常可用的 block 数
  safeMode.setBlockTotal((int)getCompleteBlocksTotal());
}
// org.apache.hadoop.hdfs.server.namenode.FSNamesystem.SafeModeInfo
private synchronized void setBlockTotal(int total) {
  this.blockTotal = total;
  // threshold 默认 0.999 ;block 正常可用少于阈值，则进入安全模式
  this.blockThreshold = (int) (blockTotal * threshold);
  this.blockReplQueueThreshold = 
    (int) (blockTotal * replQueueThreshold);
  if (haEnabled) {
    // After we initialize the block count, any further namespace
    // modifications done while in safe mode need to keep track
    // of the number of total blocks in the system.
    this.shouldIncrementallyTrackBlocks = true;
  }
  if(blockSafe < 0)
    this.blockSafe = 0;
  // 是否进去安全模式判断
  checkMode();
}
// 满足任意条件，进入安全模式
private boolean needEnter() {
  // 一：可用 block 少于设定阈值
  // 二：DataNode 正常工作不少于设定阈值；一般不设置，默认 0
  // 三：NamaNode 元数据磁盘是否充足
  return (threshold != 0 && blockSafe < blockThreshold) ||
    (datanodeThreshold != 0 && getNumLiveDataNodes() < datanodeThreshold) ||
    (!nameNodeHasResourcesAvailable());
}
```

### DataNode

NameNode 启动很多服务，基于主从架构 DataNode 必然会与之打交道。

```java
// org.apache.hadoop.hdfs.server.datanode.DataNode
/**
 * 一个集群可以有多个 DataNode，DataNode 存储数据
 * DataNode 启动后周期性跟 每个NameNode 汇报（心跳，汇报 block）
 * NameNode 不会直接操作 DataNode，而是以心跳指令返回的方式操作 DataNode
 * DataNode 也会启动 RPC 服务，供其他组件调用
 */
 // 接受 http 请求
 private HttpServer2 infoServer = null;
 private DatanodeHttpServer httpServer = null;
 // NameNode 交互
 private BlockPoolManager blockPoolManager;
 // 接受和发送 block data 服务
 DataXceiverServer xserver = null;

void startDataNode(Configuration conf, 
                    List<StorageLocation> dataDirs,
                    SecureResources resources
                    ) throws IOException {
  ...
  // DataXceiverServer: 操作 block data
  initDataXceiver(conf);
  // httpserver
  startInfoServer(conf);
  ...
  // 一个联邦对应 BPOfferService
  // 每个 NameNode 对应 一个 BPServiceActor
  // 即一个 BPOfferService 对应两个 BPServiceActor(如下图所示)
  // 向 NameNode 注册并发送心跳 => 
  //   向 NameNode 操作都由 BPServiceActor 执行
  blockPoolManager = new BlockPoolManager(this);
  blockPoolManager.refreshNamenodes(conf);
  ...
}
```

由于单个 NameNode 的内存受限导致存储 HDFS 个数有限 。在超大集群中，一般会有多个 NameNode 来管理。基于HA每个 Active NameNode 都有对应的 standby NameNode，这种形式称为联邦。

![](https://vendanner.github.io/img/hadoop/DataNode2NameNode.jpg)

#### 注册

```java
// org.apache.hadoop.hdfs.server.datanode.BPOfferService
void start() {
  for (BPServiceActor actor : bpServices) {
    actor.start();
  }
}
// org.apache.hadoop.hdfs.server.datanode.BPServiceActor
// Namenode 代理
DatanodeProtocolClientSideTranslatorPB bpNamenode;
public void run() {
  try {
    while (true) {
      // 死循环，保证注册成功
      try {
        // 注册
        connectToNNAndHandshake();
        break;
      } 
      ...
    }
    ...
    while (shouldRun()) {
      try {
        // 心跳
        offerService();
      } 
      ...
    }
    runningState = RunningState.EXITED;
  ...
}
// 注册
private void connectToNNAndHandshake() throws IOException {
  // 获取 Namenode 代理
  bpNamenode = dn.connectToNN(nnAddr);

  // NameNode 握手第一阶段：获取 NameSpace
  NamespaceInfo nsInfo = retrieveNamespaceInfo();
  ...
  // NameNode 握手第一阶段：注册
  register(nsInfo);
}
void register(NamespaceInfo nsInfo) throws IOException {
  // 创建注册信息
  bpRegistration = bpos.createRegistration();

  LOG.info(this + " beginning handshake with NN");

  while (shouldRun()) {
    // 
    try {
      // RPC 调用 NameNodeRPCServer 注册方法
      bpRegistration = bpNamenode.registerDatanode(bpRegistration);
      bpRegistration.setNamespaceInfo(nsInfo);
      break;
    } 
    ...
  }
  // 注册成功
  LOG.info("Block pool " + this + " successfully registered with NN");
  bpos.registrationSucceeded(this, bpRegistration);

  // random short delay - helps scatter the BR from all DNs
  scheduleBlockReport(dnConf.initialBlockReportDelay);
}
// org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer
@Override // DatanodeProtocol
public DatanodeRegistration registerDatanode(DatanodeRegistration nodeReg)
    throws IOException {
  checkNNStartup();
  verifySoftwareVersion(nodeReg);
  namesystem.registerDatanode(nodeReg);
  return nodeReg;
}
```

注册实质就是将 DataNode 信息添加到 NameNode 的结构体。注册时将 DataNode 信息封装成 **DatanodeDescriptor**，添加到如下结构体(主要)：

- **DatanodeManager**
  - **datanodeMap**：key = DataNodeUUID ，value = DatanodeDescriptor 
  - **host2DatanodeMap**：key = ip，value = DatanodeDescriptor
- **HeartbeatManager**
  - **stats**：DataNode 统计信息
  - **datanodes**：DatanodeDescriptor 数组

![](https://vendanner.github.io/img/hadoop/DataNodeRegisterNameNode.jpg)

#### 心跳

DataNode 周期性的向每个 NameNode 发送心跳汇报自身情况，并在返回时携带 NameNode 指令。

```java
// org.apache.hadoop.hdfs.server.datanode.BPServiceActor
while (shouldRun()) {
  try {
    final long startTime = monotonicNow();
    // 默认 3s 一个心跳
    if (startTime - lastHeartbeat >= dnConf.heartBeatInterval) {
      // 心跳携带的信息
      // datanode 名称，端口，总容量，剩余空间
      // block 信息下面单独汇报（blockReport）
      lastHeartbeat = startTime;
      if (!dn.areHeartbeatsDisabledForTests()) {
        // 发送心跳：NameNodeRPCServer.sendHeartbeat
        // 最终转到 HeartbeatManager.updateHeartbeat
        HeartbeatResponse resp = sendHeartBeat();
        assert resp != null;
        dn.getMetrics().addHeartbeat(monotonicNow() - startTime);
        bpos.updateActorStatesFromHeartbeat(
            this, resp.getNameNodeHaState());
        state = resp.getNameNodeHaState().getState();

        if (state == HAServiceState.ACTIVE) {
          handleRollingUpgradeStatus(resp);
        }

        long startProcessCommands = monotonicNow();
        // 处理心跳返回的 NameNode 指令
        if (!processCommand(resp.getCommands()))
          continue;
        long endProcessCommands = monotonicNow();
        if (endProcessCommands - startProcessCommands > 2000) {
          LOG.info("Took " + (endProcessCommands - startProcessCommands)
              + "ms to process " + resp.getCommands().length
              + " commands from NN");
        }
      }
    }
    if (sendImmediateIBR ||
        (startTime - lastDeletedReport > dnConf.deleteReportInterval)) {
      reportReceivedDeletedBlocks();
      lastDeletedReport = startTime;
    }
    // 汇报 block 信息，并处理 NameNode 指令
    List<DatanodeCommand> cmds = blockReport();
    processCommand(cmds == null ? null : cmds.toArray(new DatanodeCommand[cmds.size()]));

    DatanodeCommand cmd = cacheReport();
    processCommand(new DatanodeCommand[]{ cmd });

    // 休眠直到下一个心跳时间
    long waitTime = dnConf.heartBeatInterval - 
    (monotonicNow() - lastHeartbeat);
    synchronized(pendingIncrementalBRperStorage) {
      if (waitTime > 0 && !sendImmediateIBR) {
        try {
          pendingIncrementalBRperStorage.wait(waitTime);
        } catch (InterruptedException ie) {
          LOG.warn("BPOfferService for " + this + " interrupted");
        }
      }
    } // synchronized
  } 
  ...
  processQueueMessages();
} // while (shouldRun())
// org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager
synchronized void updateHeartbeat(final DatanodeDescriptor node,
    StorageReport[] reports, long cacheCapacity, long cacheUsed,
    int xceiverCount, int failedVolumes,
    VolumeFailureSummary volumeFailureSummary) {
  stats.subtract(node);
  // 更新 DataNode 信息和最后心跳时间 = lastUpdateMonotonic
  node.updateHeartbeat(reports, cacheCapacity, cacheUsed,
    xceiverCount, failedVolumes, volumeFailureSummary);
  // Stats 更新统计信息
  stats.add(node);
}
```

DataNode 定期上报心跳，NameNode 可根据心跳判断当前 DataNode 是否存活。

```java
// org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager
// HeartbeatManager 有心跳检测线程，在 NameNode 启动时运行
public void run() {
  while(namesystem.isRunning()) {
    try {
      final long now = Time.monotonicNow();
       // 默认 30s 检查一次
      if (lastHeartbeatCheck + heartbeatRecheckInterval < now) {
        // 心跳检查
        // 默认 10分30s 没心跳，则表示 DataNode dead
        heartbeatCheck();
        lastHeartbeatCheck = now;
      }
     ...
  }
}
// org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager
private void removeDatanode(DatanodeDescriptor nodeInfo) {
  assert namesystem.hasWriteLock();
   // 删除 stats.subtract(node);
   // 删除 datanodes.remove(node);
  heartbeatManager.removeDatanode(nodeInfo);
  blockManager.removeBlocksAssociatedTo(nodeInfo);
  // 删除
  networktopology.remove(nodeInfo);
  decrementVersionCount(nodeInfo.getSoftwareVersion());

  if (LOG.isDebugEnabled()) {
    LOG.debug("remove datanode " + nodeInfo);
  }
  // 判断是否进入安全模式
  namesystem.checkSafeMode();
}

```

- DataNode 默认 **3s** 一个心跳上传到 NameNode 更新当前 DataNode 的最后心跳时间
- NameNode 默认 **30s** 遍历所有 DataNode 的最后心跳时间，发现 **10分30s** 间隔内都没有发送心跳
  - HeartbeatManager.Stats：减去 dead DataNode 的信息
  - HeartbeatManager.datanodes：移除 dead DataNode 的信息

> 主从架构分布式系统：注册 (从节点信息添加到主节点的结构体中) 和心跳 (从节点更新心跳时间，主节点根据心跳时间判断从节点是否存活)

![](https://vendanner.github.io/img/hadoop/DataNodeHeartbearNameNode.jpg)