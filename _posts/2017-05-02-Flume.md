---
layout:     post
title:      Flume
subtitle:   
date:       2017-05-02
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - bigdata
    - Flume
---

> http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.6.0-cdh5.15.1/FlumeUserGuide.html

## 简介

`Flume` 是一个**分布式**的、**可靠**的、**高可用**的海量日志**采集**、**聚合**和**传输**系统。它的数据流模型为`Source -> Channel -> Sink`，其**事务机制**保证消息传递的**可靠性**。

![](https://vendanner.github.io/img/Flume/Flume1.png)

- `Event`：消息的基本单位，由 `header` 和 `body` 组成
- `Agent`：JVM 进程，负责将一端外部来源产生的消息**转发**到另一端外部的目的地
    - `Source`：从外部来源读入 `event`，并写入 `channel`
    - `Channel`：`event` 暂存组件，`source` 写入后，`event` 将会一直保存，直到被`Sink` 成功消费
    - `Sink`：从 `channel` 读入 `event`，并写入目的地
    
![](https://vendanner.github.io/img/Flume/Flume2.png)



## 组件

### Source 组件
对接各种**外部**数据源，将收集到的`event` 发送到 `channel` 中，一个 `source` 可以向多个 `channel` 发送 `event`，`Flume` 内置非常丰富的 `Source`，同时用户可以**自定义** `Source`

![](https://vendanner.github.io/img/Flume/Flume3.png)

#### Avro Source

![](https://vendanner.github.io/img/Flume/Flume4.png)

#### Exce Source

![](https://vendanner.github.io/img/Flume/Flume5.png)

#### Taildir Source

![](https://vendanner.github.io/img/Flume/Flume6.png)
![](https://vendanner.github.io/img/Flume/Flume7.png)

#### Kafka Source

只能接受**新**的消息，已存在的消息无法接收

![](https://vendanner.github.io/img/Flume/Flume8.png)

### Channel 组件

 - 被设计为`event` 中转**暂存区**，存储 `Source` 收集但还没被`Sink` 消费的 `event`，为了平衡 `Source` 收集和`Sink` 读取速度，可视为`Flume` 内部的**消息队列**
 - **线程安全**的并且具有**事务性**，支持 `Source` 写失败重复写和 `Sink` 读失败**重复**读操作
 
#### Memory Channel

![](https://vendanner.github.io/img/Flume/Flume9.png)
 
#### File Channel

![](https://vendanner.github.io/img/Flume/Flume10.png)
![](https://vendanner.github.io/img/Flume/Flume11.png)
![](https://vendanner.github.io/img/Flume/Flume12.png)

 
#### Kafka Channel

![](https://vendanner.github.io/img/Flume/Flume13.png)


### Interceptor 拦截器

![](https://vendanner.github.io/img/Flume/Flume14.png)

#### Timestamp Interceptor

![](https://vendanner.github.io/img/Flume/Flume15.png)

#### Host Interceptor

![](https://vendanner.github.io/img/Flume/Flume16.png)

#### Static Interceptor

![](https://vendanner.github.io/img/Flume/Flume17.png)



### Sink 组件

![](https://vendanner.github.io/img/Flume/Flume18.png)

#### Avro Sink

![](https://vendanner.github.io/img/Flume/Flume179png)

#### HDFS Sink

![](https://vendanner.github.io/img/Flume/Flume20.png)
![](https://vendanner.github.io/img/Flume/Flume21.png)
![](https://vendanner.github.io/img/Flume/Flume22.png)

#### Kafka Sink

![](https://vendanner.github.io/img/Flume/Flume23.png)
![](https://vendanner.github.io/img/Flume/Flume24.png)



### Selector 选择器

![](https://vendanner.github.io/img/Flume/Flume25.png)

#### Replicating Channel Selector

![](https://vendanner.github.io/img/Flume/Flume26.png)

#### Multiplexing Channel Selector

![](https://vendanner.github.io/img/Flume/Flume27.png)



### Sink Processor

![](https://vendanner.github.io/img/Flume/Flume28.png)

#### Load-Balancing Sink Processor

![](https://vendanner.github.io/img/Flume/Flume29.png)

#### Failover Sink Processor

![](https://vendanner.github.io/img/Flume/Flume30.png)


### 应用

#### 聚合

将运行在多台机器上的 `Flume Agent` 聚合到一台机器上。

![](https://vendanner.github.io/img/Flume/agg.png)


#### 容错处理

设置 `Sink Processors` 类型为 `failover`，将 `channel` 有优先级的输出到不同的 `Sink`，这样每个 `Sink` 连接的 `Agent` 就是不同的**数据通道**，保证**高可用** 

![](https://vendanner.github.io/img/Flume/Flume31.png)


### QA

#### Flume 优化

- Source
	- TailDir
		- 增加 filegroup 个数，增加数据采集并行度
		- batchSize：Source -> Channel 的个数(参考1万-5万)
- Channel
	- Memory
	- File
		- 多个盘符、磁盘要求高
	- capacity：当前 Channel 能存的最大 event
	- transactionCapacity：从 Source 取或者输出到 Sink 的event 最大数
	- Source/Sink：batchSize 要比 transactionCapacity 小
- Sink
	- 多个 Sink 增加吞吐量；但每个 Sink 后会再跟 Agent 进程，增大开销

`Flume Agent` 必须先保证 `failover`，若机器资源还有结余再增加 `load_balance`


#### Flume 监控

只监控 channel 的状态即可。

- JMX Reporting
- Ganglia
- JSON Reporting




## 参考资料

[Flume 1.7 修复文件重命名后重复采集数据](https://gadbees.com/flume-taildirsource/)