---
layout:     post
title:      Spark SQL 优化
subtitle:   
date:       2020-02-26
author:     danner
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Spark
    - SQL
---

一条 `SQL` 的执行顺序想必大家都了解：

- from join：数据源
- where：指定条件对记录筛选
- group by：数据分组
- 聚合函数计算
- having：条件筛选，与 group by 搭配使用
- 计算表达式
- select 字段
- order by：结果集排序

```sql
(8)SELECT (9) DISTINCT (11) <TOP_specification> <select_list>
(1) FROM <left_table>
(3) <join_type> JOIN <right_table>
(2) ON <join_condition>
(4) WHERE <where_condition>
(5) GROUP BY <group_by_list>
(6) WITH {CUBE | ROLLUP}
(7) HAVING <having_condition>
(10) ORDER BY <order_by_list>
```

以上是执行顺序的规则，但 **SQL** 最终的执行顺序在原有的基础上会做一些**优化**。在 **Spark** 中，**Catalyst** 就是 **SQL** 优化的组件。

![](https://vendanner.github.io/img/Spark/catalyst_frontend.png)

上图是 **Catalyst** 在 **Spark SQL** 中的位置，可以简化来看就是对查询计划的**优化**。

![](https://vendanner.github.io/img/Spark/catalyst_overview.png)

下面以一条有 `join` 的 **SQL** 为例，看看 **Catalyst** 做了那些优化。

```sql
SELECT sum(v) 
FROM ( SELECT t1.id,
	1 + 2 + t1.value AS v 
	FROM t1 JOIN t2
	WHERE t1.id = t2.id AND t2.id > 50 * 1000) tmp
```

 在没有 **Catalyst** 下，**SQL** 逻辑和物理计划

![](https://vendanner.github.io/img/Spark/spark_sql_login.png)

如上图所示，**SQL** 执行顺序没有做任何调整。

### Catalyst 优化

#### Predicate Pushdown

中文翻译成**谓词下推**，在 `join` 前先过滤以减少 `shuffle` 数据量

![](https://vendanner.github.io/img/Spark/Catalyst_Predicate_Pushdown.png)

#### Constant Folding

常量合并，相当于做了预处理，省去**每次**都要计算常量表达式

![](https://vendanner.github.io/img/Spark/Catalyst_Constant_Folding.png)

#### Column Pruning

列裁剪，`Scan` 时只获取需要的字段，在列式存储下可以减少 `I/O` 开销。在设计 `Spark` 外部数据源时，我们有必要去支持列裁剪的功能。

![](https://vendanner.github.io/img/Spark/Catalyst_Column_Pruning.png)

#### 最优逻辑计划

执行顺序做了调整提高整体执行效率

![](https://vendanner.github.io/img/Spark/Catalyst_Optimized_Logical_Plan.png)



 